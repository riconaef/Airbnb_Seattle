{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "The r-squared-score is: 0.5672529232782865\n"
     ]
    }
   ],
   "source": [
    "# Question 3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import seaborn as sns\n",
    "%matplotlib\n",
    "\n",
    "df = pd.read_csv('listings.csv')\n",
    "\n",
    "def separator(df):\n",
    "    '''\n",
    "    Input: pandas dataframe with a column called \"amenities\"\n",
    "    \n",
    "    Output: A new pandas dataframe which only includes the amenities column\n",
    "    \n",
    "    This function checks the different amenities and returns a new dataframe with all different amenities:\n",
    "    \n",
    "    1. Cleaning the strings and split the amenities in different rows.\n",
    "    2. Checking which amenities exist, which are available in the whole column.\n",
    "    3. Creates a new dataframe with the amenities in the columns.\n",
    "    '''\n",
    "    \n",
    "    ## Cleaning the strings and splitting each amenity into a different column\n",
    "    df['amenities'] = df['amenities'].replace('{|}| |\"', '', regex=True)\n",
    "    df['amenities'] = df['amenities'].replace(',', ' ', regex=True)\n",
    "    df_ame = pd.DataFrame(df['amenities'].str.split(expand=True))\n",
    "    \n",
    "    ## Checking which amenities exist and save them in a list \"amenities\"\n",
    "    amenities = []\n",
    "    for u in range(df_ame.shape[0]):\n",
    "        for uu in range(df_ame.shape[1]):\n",
    "            if (df_ame[uu][u] in amenities):\n",
    "                True\n",
    "            else:\n",
    "                amenities += [df_ame[uu][u]]\n",
    "    amenities = list(filter(None,amenities)) # delete None\n",
    "    df_ame = df_ame.fillna(value=np.nan)\n",
    "    \n",
    "    ## Creates a new dataframe df_new with all amenities in a separate column (1 for given, 0 for not available)  \n",
    "    df_new = pd.DataFrame(index=range(len(df_ame)), columns=amenities)\n",
    "    for i in range(len(df_new)):\n",
    "        for ii in range(df_ame.shape[1]):\n",
    "            var = df_ame.iloc[i][ii]\n",
    "            if (df_ame.iloc[i][ii] in amenities):\n",
    "                df_new[var].iloc[i] = 1\n",
    "            else:\n",
    "                False\n",
    "    df_new = df_new.fillna(0)\n",
    "    df_new = df_new.astype(int)\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "def clean_data(df, flag):\n",
    "    '''\n",
    "    INPUT\n",
    "    df - pandas dataframe \n",
    "\n",
    "    OUTPUT\n",
    "    X - A matrix holding all of the variables you want to consider when predicting the response\n",
    "    y - the corresponding response vector\n",
    "\n",
    "    This function cleans df using the following steps to produce X and y:\n",
    "    1. Optional: Use the separator function to split the amenities column if you are interested in these features\n",
    "    2. Change all columns which contain \"t\" and \"f\" into 1 and 0\n",
    "    3. Change the price columns to float variables\n",
    "    4. Change the percent columns to float variables\n",
    "    5. Drop all rows in which all rows have the same value\n",
    "    6. Drop all the object columns. (Many of them are individual for each row and disturb the processing later)\n",
    "    7. Drop rows with missing price values, create y\n",
    "    8. Drop columns which have NAN in more than 75%\n",
    "    9. Drop the columns, which include prices, additionally the \"host_listings_count\" and \"host_total_listings_count\"\n",
    "        are dropped because these columns have few outliers and disturb the processing later. \n",
    "    10. For each numeric variable in X, fill all NAN of the column with the mean value of the column.\n",
    "    '''\n",
    "\n",
    "    # Split the amenities column into the different variables with the separator function\n",
    "    # The amenities can be excluded by setting the flag to 0\n",
    "    # The separator function needs some time to run\n",
    "    if flag == 1:\n",
    "        df_ame = separator(df)\n",
    "        df = pd.concat([df,df_ame],axis=1)\n",
    "        \n",
    "    # Change the columns with \"t\" and \"f\" into 1 and 0\n",
    "    df = df.replace('t',1).replace('f',0)\n",
    "\n",
    "    # Change the dollar prices from string to float\n",
    "    dollar_column = ['price','weekly_price','monthly_price']\n",
    "    for dollar_count in dollar_column:\n",
    "        df[dollar_count] = df[dollar_count].str.replace('$', '').str.replace(',', '').astype(float)\n",
    "\n",
    "    # Change the columns with percent from string to float\n",
    "    percent_column = df.select_dtypes(include=['object']).columns\n",
    "    for percent_count in percent_column:\n",
    "        try:\n",
    "            df[percent_count] = df[percent_count].str.replace('%', '').astype(float)\n",
    "        except:\n",
    "            True\n",
    "\n",
    "    # Drop all columns in which all rows have the same value\n",
    "    nunique = df.apply(pd.Series.nunique)\n",
    "    cols_to_drop = nunique[nunique == 1].index\n",
    "    df = df.drop(cols_to_drop, axis=1)\n",
    "\n",
    "    # Drop object columns\n",
    "    cat_vars = df.select_dtypes(include=['object'])\n",
    "    df = df.drop(cat_vars,axis=1)\n",
    "    \n",
    "    # Drop rows with missing price values\n",
    "    if (df['price'].isnull().mean() != 0):\n",
    "        df = df.dropna(subset=['price'], axis=0)\n",
    "    y = df['price']\n",
    "\n",
    "    # Drop columns with more than 75% zeros\n",
    "    too_many_NAN = list(df.columns[df.isnull().mean() > 0.75])\n",
    "    for count_2 in too_many_NAN:\n",
    "        df = df.drop([count_2], axis=1)\n",
    "\n",
    "    # Drop price columns\n",
    "    df = df.drop(['price','weekly_price','monthly_price'], axis=1)\n",
    "    df = df.drop(['host_listings_count','host_total_listings_count'],axis=1)\n",
    "    \n",
    "    # Fill numeric columns with the mean\n",
    "    num_vars = df.select_dtypes(include=['float', 'int32']).columns\n",
    "    for col in num_vars:\n",
    "        df[col].fillna((df[col].mean()), inplace=True)    \n",
    "\n",
    "    X = df\n",
    "    return X, y\n",
    "\n",
    "def coef_weights(coefficients, X_train):\n",
    "    '''\n",
    "    INPUT:\n",
    "    coefficients - the coefficients of the linear model \n",
    "    X_train - the training data, so the column names can be used\n",
    "    OUTPUT:\n",
    "    coefs_df - a dataframe holding the coefficient, estimate, and abs(estimate)\n",
    "    \n",
    "    Provides a dataframe that can be used to understand the most influential coefficients\n",
    "    in a linear model by providing the coefficient estimates along with the name of the \n",
    "    variable attached to the coefficient.\n",
    "    '''\n",
    "    coefs_df = pd.DataFrame()\n",
    "    coefs_df['est_int'] = X_train.columns\n",
    "    coefs_df['coefs'] = lm_model.coef_\n",
    "    coefs_df['abs_coefs'] = np.abs(lm_model.coef_)\n",
    "    coefs_df = coefs_df.sort_values('abs_coefs', ascending=False)\n",
    "    return coefs_df\n",
    "\n",
    "# Say if amenities should be included or not\n",
    "flag = 0 # 1 for yes, 0 for no\n",
    "\n",
    "# Use the Clean_data function to create X and y\n",
    "X, y = clean_data(df, flag)\n",
    "\n",
    "# Split the data in a test and training set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state = 6)\n",
    "\n",
    "# Create a LinearRegression model with normalized data\n",
    "lm_model = LinearRegression(normalize=True)\n",
    "\n",
    "# Fit our model with the training data\n",
    "lm_model.fit(X_train,y_train)\n",
    "\n",
    "# Predict our data using our test set\n",
    "y_pred = lm_model.predict(X_test)\n",
    "\n",
    "# Compare the predicted with the test data and return the r-value\n",
    "rsquared_score = r2_score(y_test,y_pred)\n",
    "\n",
    "# Use the function\n",
    "coef_df = coef_weights(lm_model.coef_, X_train)\n",
    "\n",
    "# A quick look at the top results and the r-squared-Value\n",
    "print('The r-squared-score is: ' + str(rsquared_score))\n",
    "\n",
    "# Plot the results in a bar plot\n",
    "features = 20\n",
    "ax = plt.bar(coef_df['est_int'][:features],coef_df['abs_coefs'][:features])\n",
    "y_pos = range(len(coef_df['est_int'][:features]))\n",
    "plt.xticks(y_pos, coef_df['est_int'][:features], rotation=90)\n",
    "if flag == 0:\n",
    "    plt.title('Important features on the airbnb price\\n',fontsize = 20)\n",
    "elif flag == 1:\n",
    "    plt.title('Important features on the airbnb price (ammenities included)\\n',fontsize = 20)\n",
    "plt.ylabel('absolute coefficient')\n",
    "plt.subplots_adjust(bottom=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
